{
  "answer": "Unaelewa Kiswahili (meaning \"Kiswahili language\" in Swahili) is a NLP model developed by Google. It was trained on a large corpus of publicly available text from the internet, and it was designed to learn the patterns and relationships between words in the Kiswahili language. The model can be used for various NLP tasks such as text classification, sentiment analysis, named entity recognition, and more.",
  "context": [
    "ssing (NLP) model developed by Google.\nuser: What data was used for its training? assistant: The BER T (Bidirectional Encoder Representations from T ransformers) model was trained on a large corpus of publicly available\ntext from the internet. It was trained on a combination of books, articles, websites, and other sources to learn the language patterns and relationships between words.\nQuestion\nuser: What NLP tasks can it perform well?\nRewritten question\nWhat NLP tasks can BER T perform well?\nNow comes the actual work - please respond with the rewritten question in the same language as the question, nothing else.\nPrevious conversation\n{% for item in history %} {{item[\"role\"]}}: {{item[\"content\"]}} {% endfor %}\nQuestion\n{{question}}\nRewritten question\nfilepath: promptflow/examples/flows/chat/chat-with-pdf/chat_with_pdf/README.md content: # Chat with PDF This is a simple Python application that allow you to ask questions about\nthe content of a PDF file and get answers. It's a console application that you start w",
    "tionary with only one key \"error\" defined.\nThe value for \"error\" is a dictionary , containing \"code\", \"message\".\n\"code\" defines the error category . Currently , it may be \"UserError\" for bad user inputs and \"SystemError\" for errors inside the service.\n\"message\" is a description of the error . It can be displayed to the end user .\nHow to consume the server-sent eventsConsume using Python\nIn this sample usage, we are using the SSEClient  class. This class is not a built-in Python class and needs to be installed separately . You can install it via pip:\npip install sseclient-py   \nA sample usage would like:\nimport requests   \nfrom sseclient import SSEClient   \nfrom requests.exceptions import HTTPError   \ntry: \n    response = requests.post(url, json=body, headers=headers, stream=stream)  \n    response.raise_for_status()  \n    content_type = response.headers.get('Content-Type')  \n    if \"text/event-stream\" in content_type:  \n        client = SSEClient(response)  \n        for event in client.events():  \n            ",
    "gine string The search engine to use for the search. Default is 'google'. Yes\nnum integer The number of search results to return.Default is 10. No\nlocation string The geographic location to execute the search from. No\nsafe string The safe search mode to use for the search. Default is 'of f'.No\nOutputs\nThe json representation from serpapi query .\nEngine Return T ype Output\ngoogle json Sample  (https://serpapi.com/search-api#api-examples)\nbing json Sample  (https://serpapi.com/bing-search-api)\nfilepath: promptflow/docs/reference/tools-reference/contentsafety_text_tool.md content: # Content Safety (T ext)\nAzure Content Safety is a content moderation service developed by Microsoft that help users detect harmful content from dif ferent modalities and languages. This tool is a wrapper for\nthe Azure Content Safety T ext API, which allows you to detect text content and get moderation results. See the Azure Content Safety  (https://aka.ms/acs-doc)  for more information.Requirements\nFor AzureML users, the tool is insta",
    "e that controls the model's behavior with regards to generating rare phrases. Default is\n0.No\nOutputs\nReturn T ype Description\nstring The text of one response of conversation\nfilepath: promptflow/docs/reference/tools-reference/faiss_index_lookup_tool.md content: # Faiss Index Lookup\nFaiss Index Lookup is a tool tailored for querying within a user-provided Faiss-based vector store. In combination with our Large Language Model (LLM) tool, it empowers users to\nextract contextually relevant information from a domain knowledge base.\nRequirements\nFor AzureML users, the tool is installed in default image, you can use the tool without extra installation.\nFor local users, if your index is stored in local path,\npip install promptflow-vectordb\nif your index is stored in Azure storage,\npip install promptflow-vectordb[azure]\nPrerequisites\nFor AzureML users,\nstep 1. Prepare an accessible path on Azure Blob Storage. Here's the guide if a new storage account needs to be created: Azure Storage Account\n(https://learn.microsoft",
    "\"temperature\":0.4}. Default:No\ndeployment_name stringThe name of the deployment to target on the Online Inferencing endpoint. If no value is passed,\nthe Inferencing load balancer traf fic settings will be used.No\nprompt string The text prompt that the language model will use to generate it's response. Yes\nOutputs\nAPI Return T ype Description\nCompletion string The text of one predicted completion\nChat string The text of one response int the conversation\nDeploying to an Online Endpoint\nWhen deploying a flow containing the Open Model LLM tool to an online endpoint, there is an additional step to setup permissions. During deployment through the web pages, there\nis a choice between System-assigned and User-assigned Identity types. Either way , using the Azure Portal (or a similar functionality), add the \"Reader\" Job function role to the\nidentity on the Azure Machine Learning workspace or Ai Studio project which is hosting the endpoint. The prompt flow deployment may need to be refreshed.\nfilepath: promptflow/docs/"
  ],
  "issue_addressed": ""
}