$schema: https://azuremlschemas.azureedge.net/promptflow/latest/Flow.schema.json
environment:
  python_requirements_txt: requirements.txt
inputs:
  chat_history:
    type: list
    default: []
  pdf_url:
    type: string
    default: http://127.0.0.1:5000/get_pdf
  question:
    type: string
    is_chat_input: true
    default: Does promptflow support evaluation?
  config:
    type: object
    default:
      EMBEDDING_MODEL_DEPLOYMENT_NAME: text-embedding-ada-002
      CHAT_MODEL_DEPLOYMENT_NAME: gpt-4
      PROMPT_TOKEN_LIMIT: 3000
      MAX_COMPLETION_TOKENS: 1024
      VERBOSE: true
      CHUNK_SIZE: 1024
      CHUNK_OVERLAP: 64
  issue:
    type: string
    default: "'[BUG] no module named promptflow.runtime'"
outputs:
  answer:
    type: string
    is_chat_output: true
    reference: ${qna_tool.output.answer}
  context:
    type: string
    reference: ${find_context_tool.output.context}
  issue_addressed:
    type: string
    reference: ${issues.output}
nodes:
- name: setup_env
  type: python
  source:
    type: code
    path: setup_env.py
  inputs:
    connection: frisk
    config: ${inputs.config}
- name: download_tool
  type: python
  source:
    type: code
    path: download_tool.py
  inputs:
    url: ${inputs.pdf_url}
    env_ready_signal: ${setup_env.output}
- name: build_index_tool
  type: python
  source:
    type: code
    path: build_index_tool.py
  inputs:
    pdf_path: ${download_tool.output}
- name: find_context_tool
  type: python
  source:
    type: code
    path: find_context_tool.py
  inputs:
    question: ${rewrite_question_tool.output}
    index_path: ${build_index_tool.output}
- name: qna_tool
  type: python
  source:
    type: code
    path: qna_tool.py
  inputs:
    prompt: ${find_context_tool.output.prompt}
    history: ${inputs.chat_history}
- name: rewrite_question_tool
  type: python
  source:
    type: code
    path: rewrite_question_tool.py
  inputs:
    question: ${inputs.question}
    history: ${inputs.chat_history}
    env_ready_signal: ${setup_env.output}
- name: issues
  type: llm
  source:
    type: code
    path: issues.jinja2
  inputs:
    deployment_name: gpt-4
    response_format:
      type: json_object
    issue: ${inputs.issue}
  connection: frisk
  api: chat
